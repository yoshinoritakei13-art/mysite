{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3webアプリ作成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目次：https://docs.google.com/document/d/1eDw9PK5Ft0vImu81e7oERB_q-dZvxbFe8bGetZBgEEg/edit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 応用実装"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ④OCRアプリ\n",
    "\n",
    "\n",
    ">アプリの概要\n",
    "\n",
    "<img src=\"pic/img042.png\">\n",
    "\n",
    "デプロイ先：https://ocr-step2-ver6-d89jchryrlb.streamlit.app/\n",
    "\n",
    ">動作を構成してる部品の紹介（APIやライブラリ）\n",
    "画像認識外部ツール\n",
    "- Tesseract-OCR\n",
    "    - 目的：python環境内でTesseract-OCRを活用して、画像から文字認識をする\n",
    "    - 参考：https://github.com/tesseract-ocr/tessdoc\n",
    "\n",
    "ライブラリ\n",
    "- streamlit\n",
    "    - 目的：画像分析をするためのUIを表示するためのフロントエンドを生成する\n",
    "- pyocr\n",
    "    - 目的：外部ツールTesseract-OCRをpythonで活用するためのライブラリ\n",
    "- pillow\n",
    "    - 目的：python内で画像を読み込んで、Tesseract-OCRに画像データを渡すために使う\n",
    "- asari\n",
    "    - 目的：文字から簡易的な感情分析をするために使う\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">ライブラリのインストール\n",
    "\n",
    "外部ツール\n",
    "- Tesseract-OCR\n",
    "    - Windowsの場合：tesseract-ocr-w64-setup-5.3.1.20230401.exeでインストール\n",
    "        - インストーラーのDL場所：https://github.com/UB-Mannheim/tesseract/wiki\n",
    "    - 2015年以前のintelCPU搭載Macの場合：brewコマンドでインストール\n",
    "        - brew install tesseract\n",
    "        - brew install tesseract-lang\n",
    "    - M1チップなどのappleシリコンのMacの場合：condaでインストール\n",
    "        - conda install -c conda-forge tesseract\n",
    "\n",
    "\n",
    "ライブラリ\n",
    "- streamlit\n",
    "    - pip install streamlit\n",
    "- pyocr\n",
    "    - pip install pyocr\n",
    "- Pillow\n",
    "    - pip install Pillow\n",
    "- asari\n",
    "    - pip install asari\n",
    "\n",
    "\n",
    "\n",
    ">ライブラリの公式ドキュメントの見方や使い方を説明\n",
    "\n",
    "ライブラリ\n",
    "\n",
    "- streamlit\n",
    "    - インストール方法はget startページで確認\n",
    "    - 参考：https://docs.streamlit.io/library/get-started/installation\n",
    "    - st.titleなどはコンポーネントページから確認出来る\n",
    "    - 参考：https://streamlit.io/components\n",
    "- pyocr\n",
    "    - pyocr.get_available_tools()で使用できるOCRツールを検知してengine.image_to_string(画像情報)でocrを使った画像分析を開始\n",
    "    - 本来は公式ですが、公式に使い方の情報ないので、エンジニアが共有しているコミュニティを活用させていただきます。\n",
    "    - コード参考：https://qiita.com/ku_a_i/items/93fdbd75edacb34ec610\n",
    "    - なにも説明がない公式：https://pypi.org/project/pyocr/\n",
    "- Pillow\n",
    "    - Image.open(画像ファイルの場所)でpython環境内に画像ファイルを読み込む\n",
    "    - 参考：https://pillow.readthedocs.io/en/stable/\n",
    "- asari\n",
    "    - sonar.ping(text=感情分析したい文字)で感情分析の結果が得られます。\n",
    "    - 参考：https://pypi.org/project/asari/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">それぞれの機能をjupyterで動く最小限を作る"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下がjuptyterにて動く最低限のアプリの流れです。\n",
    "\n",
    "1. 作るアプリの全体のコードを把握\n",
    "1. それぞれ機能を解説\n",
    "    1. 外部OCRを活用するpyocrの仕様\n",
    "    1. 画像解析\n",
    "    1. 簡易的な感情分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.全体のコード"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使うアプリの全体像は下記のようになります。  \n",
    "これはweb上では動きませんが、手元では動作するアプリです。\n",
    "\n",
    "以下のコードの動作の流れ\n",
    "1. 拡張機能であるライブラリをインポート\n",
    "1. 外部OCRの準備\n",
    "    1. ライブラリpyocrに外部ツールであるtesseractがどこにあるかを指定\n",
    "    1. ライブラリpyocrが認識している外部ツールを設定し、engineに代入\n",
    "1. 外部OCRを使って画像解析\n",
    "    1. engine.image_to_stringで画像から文字読み取り\n",
    "1. 画像から文字読み取った文字から感情分析\n",
    "    1. 拡張機能であるライブラリをインポート\n",
    "    1. sonar.pingで文字から簡易的な感情分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字認識アプリ\n",
      "moji.png\n"
     ]
    },
    {
     "ename": "TesseractError",
     "evalue": "(1, b'Error opening data file /usr/local/share/tessdata/jpn.traineddata\\nPlease make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\\nFailed loading language \\'jpn\\'\\nTesseract couldn\\'t load any languages!\\nCould not initialize tesseract.\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTesseractError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m engine \u001b[39m=\u001b[39m engines[\u001b[39m0\u001b[39m] \u001b[39m# ツールを複数選択して、エラーにならないように１つだけ選択\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# 画像の文字を読み込む\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m txt \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mimage_to_string(Image\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39mmoji.png\u001b[39;49m\u001b[39m\"\u001b[39;49m), lang\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mjpn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(txt) \u001b[39m# 分析結果を表示\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m感情分析の結果\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# 案内表示\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tech0/lib/python3.8/site-packages/pyocr/tesseract.py:372\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, builder)\u001b[0m\n\u001b[1;32m    367\u001b[0m (status, errors) \u001b[39m=\u001b[39m run_tesseract(\u001b[39m\"\u001b[39m\u001b[39minput.bmp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m, cwd\u001b[39m=\u001b[39mtmpdir,\n\u001b[1;32m    368\u001b[0m                                  lang\u001b[39m=\u001b[39mlang,\n\u001b[1;32m    369\u001b[0m                                  flags\u001b[39m=\u001b[39mbuilder\u001b[39m.\u001b[39mtesseract_flags,\n\u001b[1;32m    370\u001b[0m                                  configs\u001b[39m=\u001b[39mbuilder\u001b[39m.\u001b[39mtesseract_configs)\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m status:\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mraise\u001b[39;00m TesseractError(status, errors)\n\u001b[1;32m    374\u001b[0m tested_files \u001b[39m=\u001b[39m []\n\u001b[1;32m    375\u001b[0m output_file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mERROR\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTesseractError\u001b[0m: (1, b'Error opening data file /usr/local/share/tessdata/jpn.traineddata\\nPlease make sure the TESSDATA_PREFIX environment variable is set to your \"tessdata\" directory.\\nFailed loading language \\'jpn\\'\\nTesseract couldn\\'t load any languages!\\nCould not initialize tesseract.\\n')"
     ]
    }
   ],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "from PIL import Image # 画像扱うための機能をインポート\n",
    "import pyocr # 外部OCRを扱うための機能をインポート\n",
    "import platform # OSの判別するために、プラットフォームを読み込む機能をインポート\n",
    "\n",
    "# それぞれのOSにインストールされるtesseractの場所を指定\n",
    "# ※講義のためにmacでもwindowsでも動くように指定しています。\n",
    "# ※macでエラーが出る場合は、ターミナルで「which tesseract」を実行して、出力されたパスをpyocr.tesseract.TESSERACT_CMDに設定してください。\n",
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "print(\"文字認識アプリ\") # タイトル表示\n",
    "\n",
    "print(\"moji.png\") # 画像分析する画像を表示\n",
    "\n",
    "# OCRエンジンを取得\n",
    "engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択\n",
    "\n",
    "# 画像の文字を読み込む\n",
    "# engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\n",
    "txt = engine.image_to_string(Image.open(\"moji.png\"), lang=\"jpn\")\n",
    "print(txt) # 分析結果を表示\n",
    "\n",
    "print(\"感情分析の結果\") # 案内表示\n",
    "from asari.api import Sonar # 文字から感情分析する機能をインポート\n",
    "sonar = Sonar() # Sonar()をsonarに代入\n",
    "res = sonar.ping(text=txt) # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入\n",
    "print(res[\"classes\"]) # res[\"classes\"]に結果が変えて来るので、これを表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.それぞれ機能を解説"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 外部OCRを活用するpyocrの仕様"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyocrは外部ツールとしてtesseractを活用するため、必ずインストールとツールの位置の指定が必要です。  \n",
    "\n",
    "ツールの位置の指定はpyocr.tesseract.TESSERACT_CMDを使います。  \n",
    "また、指定した場所からpyocrが読み込んだツールを.get_available_toolsで呼び出すことができます。\n",
    "\n",
    "pyocr.get_available_tools()に何もなければ、インストールがうまくいっていないので、  \n",
    "以下のコードのように、必ずmodule 'pyocr.tesseract'が出力されるようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<module 'pyocr.tesseract' from 'c:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\pyocr\\\\tesseract.py'>]\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "print(engines)\n",
    "\n",
    "# 次のコードがエラーにならないように、ツールを選択してengineを定義しておく。\n",
    "engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2画像解析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像解析は以下のコードでできます。  \n",
    "engine.image_to_string(Image.open(ここに画像のファイル名), lang=ここに言語)\n",
    "\n",
    "注意点として、言語コードがjaではなく、jpnになっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'寿限無 寿限無 五却のすりきれ\\n\\n海砂利水魚の水行末 雲来未 風来未\\n\\n食う寝るところに住むところ\\n\\nやぶら小路のぶら小路\\n\\nパイボポパイポ パイポのシューリンガン\\n\\nシューリンガンのクーリンダイ\\n\\nクーリンダイのポンポコナーのポンポコピーの長久命の長助'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.image_to_string(Image.open(\"moji.png\"), lang=\"jpn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3簡易的な感情分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字からの感情分析は以下のコードでできます。  \n",
    "Sonar().ping(text=ここに文字列)\n",
    "\n",
    "結果はjsonとして返ってきます。  \n",
    "この講座では、この結果が見やすいので、そのまま活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'おはようございます',\n",
       " 'top_class': 'positive',\n",
       " 'classes': [{'class_name': 'negative', 'confidence': 0.009979760274291039},\n",
       "  {'class_name': 'positive', 'confidence': 0.9900202751159668}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sonar().ping(text=\"おはようございます\") # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上がアプリの動作部分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">streamlitに実装する場合の使う機能"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今はユーザーがブラウザ上で選択したりなど、想定していませんが、  \n",
    "選択肢の表示などのコンポーネントを紹介します。\n",
    "\n",
    "※streamlitはjupyterでは動作せず、実行ファイルでのみ動作します"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "タイトルは  \n",
    "st.title(\"ここにタイトル\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただの表示は  \n",
    "st.write(\"ここに表示したい文字\")\n",
    "\n",
    "ただし、再読み込みしない限り、この表示された文字は変更されません。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の表示は  \n",
    "st.image(\"ここにファイル名\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選択肢は  st.selectbox(\"ここに表示したい項目名\",ここに配列のデータ)  \n",
    "でできます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイルアップロードする機能は  \n",
    "st.file_uploader(\"ここに表示したい文字\",type=ここに許可する拡張子の配列)  \n",
    "でできます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の機能を使ってwebアプリにしていきます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">（演習）streamlitに実装しましょう！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動いたアプリをstreamlitで動くようにします。  \n",
    "この演習では必ず実行ファイルにコーディングしてください。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※streamlit run ファイル名で実行する時は必ず実行ファイルで実行してください。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装の流れ\n",
    "1. 固定である画像ファイルをアップロードされた画像ファイルに変更\n",
    "    1. アップローダー設置\n",
    "    1. アップロードされたら画像解析のコードが実行されるようにする\n",
    "1. 画像解析の認識の言語指定を変更できるようにする\n",
    "    1. 言語候補を変数へ\n",
    "    1. セレクトボックスで選択できるようにする\n",
    "1. ターミナルに出力していた文字などをブラウザに出力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の手元で動いたコードをstreamlitで動くようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "from PIL import Image # 画像扱うための機能をインポート\n",
    "import pyocr # 外部OCRを扱うための機能をインポート\n",
    "import platform # OSの判別するために、プラットフォームを読み込む機能をインポート\n",
    "\n",
    "# それぞれのOSにインストールされるtesseractの場所を指定\n",
    "# ※講義のためにmacでもwindowsでも動くように指定しています。\n",
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "print(\"文字認識アプリ\") # タイトル表示\n",
    "\n",
    "print(\"moji.png\") # 画像分析する画像を表示\n",
    "\n",
    "# OCRエンジンを取得\n",
    "engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択\n",
    "\n",
    "# 画像の文字を読み込む\n",
    "# engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\n",
    "txt = engine.image_to_string(Image.open(\"moji.png\"), lang=\"jpn\")\n",
    "print(txt) # 分析結果を表示\n",
    "\n",
    "print(\"感情分析の結果\") # 案内表示\n",
    "from asari.api import Sonar # 文字から感情分析する機能をインポート\n",
    "sonar = Sonar() # Sonar()をsonarに代入\n",
    "res = sonar.ping(text=txt) # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入\n",
    "print(res[\"classes\"]) # res[\"classes\"]に結果が変えて来るので、これを表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.固定である画像ファイルをアップロードされた画像ファイルに変更"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1アップローダー設置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込みが固定だったmoji.pngをアップローダーからの音声ファイルに変更します。\n",
    "\n",
    "ファイルアップロードする機能は  \n",
    "st.file_uploader(\"ここに表示したい文字\",type=ここに許可する拡張子の配列)  \n",
    "でできます。\n",
    "\n",
    "今回は許可する拡張子の配列をpngとjpgにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesseractが認識できるpngとjpgだけを許可するアップローダーの設置\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"png\",\"jpg\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、アップロードされたファイルがfile_uploadに代入されます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2アップロードされたら画像解析のコードが実行されるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動くコードは、無条件にファイルの画像分析をするコードを実行してしまうので、  \n",
    "これをif文を使ってアップロードされた時だけ、画像分析をするコードを実行するようにします。\n",
    "\n",
    "st.file_uploaderはなにもアップロードされていない場合、なにも存在しないNoneという値になるので、  \n",
    "file_upload != Noneという条件を使います。\n",
    "\n",
    "if文を使った条件は以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesseractが認識できるpngとjpgだけを許可するアップローダーの設置\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"png\",\"jpg\"])\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    print(\"ここに画像分析をするコード\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アップローダーと実行条件を手元のコードに反映させると以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "from PIL import Image # 画像扱うための機能をインポート\n",
    "import pyocr # 外部OCRを扱うための機能をインポート\n",
    "import platform # OSの判別するために、プラットフォームを読み込む機能をインポート\n",
    "\n",
    "# それぞれのOSにインストールされるtesseractの場所を指定\n",
    "# ※講義のためにmacでもwindowsでも動くように指定しています。\n",
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "print(\"文字認識アプリ\") # タイトル表示\n",
    "\n",
    "\n",
    "\n",
    "# OCRエンジンを取得\n",
    "engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択\n",
    "\n",
    "# tesseractが認識できるpngとjpgだけを許可するアップローダーの設置\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"png\",\"jpg\"])\n",
    "print(file_upload) # 画像分析する画像を表示\n",
    "if (file_upload !=None):\n",
    "    # 画像の文字を読み込む\n",
    "    # engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\n",
    "    txt = engine.image_to_string(Image.open(file_upload), lang=\"jpn\")\n",
    "    print(txt) # 分析結果を表示\n",
    "\n",
    "    print(\"感情分析の結果\") # 案内表示\n",
    "    from asari.api import Sonar # 文字から感情分析する機能をインポート\n",
    "    sonar = Sonar() # Sonar()をsonarに代入\n",
    "    res = sonar.ping(text=txt) # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入\n",
    "    print(res[\"classes\"]) # res[\"classes\"]に結果が変えて来るので、これを表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.画像分析の言語指定を変更できるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像分析が日本語である\"jpn\"で固定なので、これをセレクトボックスで選択し、反映できるようにします。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1言語候補を変数へ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"jpn\"を変数にします。\n",
    "\n",
    "変数set_language_listに言語コードの辞書型配列を作ります。  \n",
    "ここでは日本語と英語にしておきます。\n",
    "\n",
    "英語の言語コードはengです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像読み込みのための言語と言語のコードを変換するリストを設定\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"jpn\",\n",
    "    \"英語\" :\"eng\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セレクトボックスで日本語または英語を選択し、set_language_listで言語コードに変換することで、  \n",
    "画像分析に必要な言語コードを変数化します。\n",
    "\n",
    "日本語文字は.keys()で取得できるので、これを活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['日本語', '英語'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_language_list.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2セレクトボックスで選択できるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この２つの選択肢をセレクトボックスに適応します。\n",
    "\n",
    "セレクトボックスは  st.selectbox(\"ここに表示したい項目名\",ここに配列のデータ)でできます。  \n",
    "この選ばれた選択肢をset_languageに代入します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これによって、ユーザーに見える選択肢は、set_languageである['日本語', '英語']から取得し、   \n",
    "コード実行側では、 set_language_list[set_language]とすることで、言語コードを指定します。\n",
    "\n",
    "まとめると以下のようなコードになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "from PIL import Image # 画像扱うための機能をインポート\n",
    "import pyocr # 外部OCRを扱うための機能をインポート\n",
    "import platform # OSの判別するために、プラットフォームを読み込む機能をインポート\n",
    "\n",
    "# それぞれのOSにインストールされるtesseractの場所を指定\n",
    "# ※講義のためにmacでもwindowsでも動くように指定しています。\n",
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "\n",
    "# 画像読み込みのための言語と言語のコードを変換するリストを設定\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"jpn\",\n",
    "    \"英語\" :\"eng\",\n",
    "}\n",
    "\n",
    "\n",
    "print(\"文字認識アプリ\") # タイトル表示\n",
    "\n",
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys()) # 言語選択のためのリスト\n",
    "\n",
    "\n",
    "\n",
    "# OCRエンジンを取得\n",
    "engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択\n",
    "\n",
    "# tesseractが認識できるpngとjpgだけを許可するアップローダーの設置\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"png\",\"jpg\"])\n",
    "print(file_upload)  # 画像分析する画像を表示\n",
    "if (file_upload !=None):\n",
    "    # 画像の文字を読み込む\n",
    "    # engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\n",
    "    txt = engine.image_to_string(Image.open(file_upload), lang=set_language_list[set_language])\n",
    "    print(txt) # 分析結果を表示\n",
    "\n",
    "    print(\"感情分析の結果\") # 案内表示\n",
    "    from asari.api import Sonar # 文字から感情分析する機能をインポート\n",
    "    sonar = Sonar() # Sonar()をsonarに代入\n",
    "    res = sonar.ping(text=txt) # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入\n",
    "    print(res[\"classes\"]) # res[\"classes\"]に結果が変えて来るので、これを表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.ターミナルに出力していた文字などをブラウザに出力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後にprintでターミナルで出力していた  \n",
    "タイトルや文字や音声を以下の４つのコードを使ってブラウザに出力します。\n",
    "\n",
    "- st.title\n",
    "- st.write\n",
    "- st.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "from PIL import Image # 画像扱うための機能をインポート\n",
    "import pyocr # 外部OCRを扱うための機能をインポート\n",
    "import platform # OSの判別するために、プラットフォームを読み込む機能をインポート\n",
    "\n",
    "# それぞれのOSにインストールされるtesseractの場所を指定\n",
    "if platform.system() == \"Windows\":\n",
    "    pyocr.tesseract.TESSERACT_CMD = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "else:\n",
    "    pyocr.tesseract.TESSERACT_CMD = r\"/usr/local/bin/tesseract\"\n",
    "\n",
    "# 画像読み込みのための言語と言語のコードを変換するリストを設定\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"jpn\",\n",
    "    \"英語\" :\"eng\",\n",
    "}\n",
    "\n",
    "st.title(\"文字認識アプリ\") # タイトル表示\n",
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys()) # 言語選択のためのリスト\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"png\",\"jpg\"]) # tesseractが認識できるpngとjpgだけを許可するアップローダーの設置\n",
    "\n",
    "# アップロードされたらfile_uploadがNoneではなくなるので、実行される\n",
    "if (file_upload !=None):\n",
    "\n",
    "    st.image(file_upload) # 画像分析する画像を表示\n",
    "\n",
    "    # OCRエンジンを取得\n",
    "    engines = pyocr.get_available_tools() # pyocrが認識できるOCR外部ツールを検知\n",
    "    engine = engines[0] # ツールを複数選択して、エラーにならないように１つだけ選択\n",
    "\n",
    "    # 画像の文字を読み込む\n",
    "    # engine.image_to_string(開いた画像,画像認識する言語)で画像分析開始し、分析結果をtxtに代入\n",
    "    txt = engine.image_to_string(Image.open(file_upload), lang=set_language_list[set_language])\n",
    "    st.write(txt) # 分析結果を表示\n",
    "\n",
    "    st.write(\"感情分析の結果\") # 案内表示\n",
    "    from asari.api import Sonar # 文字から感情分析する機能をインポート\n",
    "    sonar = Sonar() # Sonar()をsonarに代入\n",
    "    res = sonar.ping(text=txt) # sonar.ping(text=分析したい文字)で感情分析リクエストし、結果をresに代入\n",
    "    st.write(res[\"classes\"]) # res[\"classes\"]に結果が変えて来るので、これを表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14498c2693dbacc748b33ada8a31e4cf5c4288efbd86c8d200c58bb6fc8893c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
