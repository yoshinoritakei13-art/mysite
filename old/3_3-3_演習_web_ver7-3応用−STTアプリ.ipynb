{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3webアプリ作成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目次：https://docs.google.com/document/d/1eDw9PK5Ft0vImu81e7oERB_q-dZvxbFe8bGetZBgEEg/edit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 応用実装"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ③STTアプリ\n",
    "\n",
    ">アプリの概要\n",
    "\n",
    "<img src=\"pic/img041.png\">\n",
    "\n",
    ">動作を構成してる部品の紹介（APIやライブラリ）\n",
    "API\n",
    "- SpeechRecognizer\n",
    "    - 目的：googleが提供しているフリーで音声認識を活用したライブラリを使って、マイクまたは音声ファイルから音声認識をします。\n",
    "    - 参考：https://github.com/Uberi/speech_recognition\n",
    "\n",
    "ライブラリ\n",
    "- streamlit\n",
    "    - 目的：音声認識をするためのUIを表示するためのフロントエンドを生成する\n",
    "- SpeechRecognition\n",
    "    - 目的：音声認識をするために使う\n",
    "- pyaudio\n",
    "    - 目的：SpeechRecognitionがマイク入力するために活用される\n",
    "\n",
    ">ライブラリのインストール\n",
    "\n",
    "ライブラリ\n",
    "- windowsの方(2015年以前のintelCPU搭載macの方)\n",
    "    - streamlit\n",
    "        - pip install streamlit\n",
    "    - SpeechRecognition\n",
    "        - pip install SpeechRecognition\n",
    "    - pyaudio\n",
    "        - pip install pyaudio\n",
    "- macの方（M1チップなどのappleシリコンの方）\n",
    "    - streamlit\n",
    "        - pip install streamlit\n",
    "    - SpeechRecognition\n",
    "        - conda install -c conda-forge speechrecognition\n",
    "    - pyaudio\n",
    "        - conda install -c anaconda pyaudio\n",
    "    - portaudio\n",
    "        - conda install -c anaconda portaudio\n",
    "    - libflac\n",
    "        - conda install -c conda-forge libflac\n",
    "\n",
    ">ライブラリの公式ドキュメントの見方や使い方を説明\n",
    "\n",
    "ライブラリ\n",
    "\n",
    "- streamlit\n",
    "    - インストール方法はget startページで確認\n",
    "    - 参考：https://docs.streamlit.io/library/get-started/installation\n",
    "    - st.titleなどはコンポーネントページから確認出来る\n",
    "    - 参考：https://streamlit.io/components\n",
    "- SpeechRecognition\n",
    "    - r.recognize_google(オーディオファイル)で音声認識を開始する\n",
    "    - 参考：https://www.kkaneko.jp/ai/win/speechrecog.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">それぞれの機能をjupyterで動く最小限を作る"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下がjuptyterにて動く最低限のアプリの流れです。\n",
    "\n",
    "1. 作るアプリの全体のコードを把握\n",
    "1. それぞれ機能を解説\n",
    "    1. ファイルからの音声認識\n",
    "    1. マイクからの音声認識\n",
    "    1. 音声認識失敗した時の対策として、try構文を使う"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.全体のコード"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使うアプリの全体像は下記のようになります。  \n",
    "これはweb上では動きませんが、手元では動作するアプリです。\n",
    "\n",
    "以下のコードの動作の流れ\n",
    "1. 拡張機能であるライブラリをインポート\n",
    "1. 2つの方法の音声認識を関数として用意\n",
    "    1. 音声ファイルから音声認識\n",
    "    1. マイクから音声認識\n",
    "1. 音声認識実行\n",
    "    1. sample.wavを指定して、これを用意した関数である音声ファイルから音声認識で文字起こし\n",
    "    1. マイクを使用して、用意した関数であるマイクから音声認識で文字起こし\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字起こしアプリ\n",
      "音声認識結果:\n",
      "音声認識のテスト\n",
      "sample.wav\n",
      "音声認識結果:\n",
      "音声認識に失敗しました\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "import speech_recognition as sr # 音声認識の機能をインポート\n",
    "\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "def file_speech_to_text(audio_file):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "def mic_speech_to_text():\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "print(\"文字起こしアプリ\") # タイトル\n",
    "\n",
    "file_upload = \"sample.wav\"\n",
    "\n",
    "print(\"音声認識結果:\") # 案内表示\n",
    "result_text = file_speech_to_text(file_upload) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "print(result_text) # メソッドから返ってきた値を表示\n",
    "print(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "\n",
    "result_text = mic_speech_to_text() # 選択した言語を元に音声認識開始\n",
    "print(\"音声認識結果:\") # 案内表示に変更\n",
    "print(result_text) # メソッドから返ってきた値を表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.それぞれ機能を解説"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1ファイルからの音声認識"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声認識をリクエストする前準備として、音声ファイルの解析準備をします。\n",
    "\n",
    "ファイルからの音声認識は音声ファイルであるsample.wavをsr.AudioFileで開き、変数sourceに代入します。\n",
    "\n",
    "sr.Recognizer().record(source)でそのファイルをレコードします。  \n",
    "コードは以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声ファイルを読み込み\n",
    " # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "with sr.AudioFile(\"sample.wav\") as source:\n",
    "    audio = sr.Recognizer().record(source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に用意した音声ファイルを  \n",
    "sr.Recognizer().recognize_google(用意した音声ファイル, language=ここに言語指定)  \n",
    "で音声認識ができます。\n",
    "\n",
    "言語指定は日本語だとjaになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'音声認識のテスト'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声認識のコードをまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声ファイルを読み込み\n",
    "\n",
    " # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "# 読み込んだファイルで音声認識開始\n",
    "with sr.AudioFile(\"sample.wav\") as source:\n",
    "    audio = sr.Recognizer().record(source)\n",
    "\n",
    "sr.Recognizer().recognize_google(audio, language=\"ja\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動くアプリはこの機能を関数として呼び出せるようにしてあります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2マイクからの音声認識"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声認識をリクエストする前準備として、マイクの音声の解析準備をします。\n",
    "\n",
    "ファイルからの音声認識と違い、sr.Microphone()そのものを変数sourceに代入します。\n",
    "\n",
    "audio = sr.Recognizer().listen(source)でそのファイルをレコードします。  \n",
    "コードは以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マイク入力を音声ファイルとして読み込み\n",
    "\n",
    " # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    audio = sr.Recognizer().listen(source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に用意した音声情報を  \n",
    "sr.Recognizer().recognize_google(用意した音声ファイル, language=ここに言語指定)  \n",
    "で音声認識します。\n",
    "\n",
    "言語指定は日本語だとjaになります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マイクで入力された音声を音声認識開始\n",
    "\n",
    " #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "\n",
    "sr.Recognizer().recognize_google(audio, language=\"ja\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もしマイク入力が検知されない場合は、pythonが別のオーディオを監視している可能性があるので、pythonが検知しているオーディオデバイスの一覧を確認して、オーディオデバイスを指定しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr.Microphoneが認識しているデバイスをすべて書き出し\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(\"Microphone with name \\\"{1}\\\" found for `Microphone(device_index={0})`\".format(index, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # 指定したいデバイスのindex番号\n",
    "\n",
    "with sr.Microphone(device_index=i) as source:\n",
    "    audio = sr.Recognizer().listen(source)\n",
    "sr.Recognizer().recognize_google(audio, language=\"ja\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声認識のコードをまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マイク入力を音声ファイルとして読み込み\n",
    "\n",
    " # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "# マイクで入力された音声を音声認識開始\n",
    "\n",
    "#  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    audio = sr.Recognizer().listen(source)\n",
    "\n",
    "sr.Recognizer().recognize_google(audio, language=\"ja\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動くアプリはこの機能を関数として呼び出せるようにしてあります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3音声認識失敗した時の対策として、try構文を使う"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声が入力されていないなど、音声認識できない場合は、  \n",
    "認識無しではなく、エラーとしてコード実行が止まってしまします。\n",
    "\n",
    "何も音声を入力しなかった場合のエラーが以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マイク入力を音声ファイルとして読み込み\n",
    "\n",
    " # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "# マイクで入力された音声を音声認識開始\n",
    "\n",
    " #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    audio = sr.Recognizer().listen(source) \n",
    "\n",
    "try:\n",
    "    text = sr.Recognizer().recognize_google(audio, language=\"ja\")\n",
    "except:\n",
    "    text = \"音声認識に失敗しました\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そうならないためにtry構文でエラーを条件にコード実行を変更します。\n",
    "\n",
    "try構文はifと同じようにコーディングします。  \n",
    "ifのは、ifとelseでしたが、tryはtryとexceptを使います。\n",
    "\n",
    "コードは以下のようになります。  \n",
    "同じように実行してもエラーにならなくなりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マイク入力を音声ファイルとして読み込み\n",
    "\n",
    " # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "\n",
    "    # マイクで入力された音声を音声認識開始\n",
    "    #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上がアプリの動作部分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">streamlitに実装する場合の使う機能"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今はユーザーがブラウザ上で選択したりなど、想定していませんが、  \n",
    "選択肢の表示などのコンポーネントを紹介します。\n",
    "\n",
    "※streamlitはjupyterでは動作せず、実行ファイルでのみ動作します"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "タイトルは  \n",
    "st.title(\"ここにタイトル\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただの表示は  \n",
    "st.write(\"ここに表示したい文字\")\n",
    "\n",
    "ただし、再読み込みしない限り、この表示された文字は変更されません。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数を監視して表示させる方法は以下のようになります。\n",
    "1. 表示させる場所を確保する\n",
    "1. その空間に.writeで書き込みをする\n",
    "\n",
    "例として、変数testを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = st.empty()\n",
    "test.write(\"ここに書き込みたい事\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選択肢は  st.selectbox(\"ここに表示したい項目名\",ここに配列のデータ)  \n",
    "でできます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開いたオーディオファイルは   \n",
    "st.audio(ここに開いたオーディオファイル)  \n",
    "でブラウザ上に表示可能です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボタン機能は  \n",
    "st.button(\"ここに表示したい文字\")  \n",
    "でできます。\n",
    "\n",
    "この生成されたボタンは押されていない状態でFalse、押された瞬間にTrueになります。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイルアップロードする機能は  \n",
    "st.file_uploader(\"ここに表示したい文字\",type=ここに許可する拡張子の配列)  \n",
    "でできます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の機能を使ってwebアプリにしていきます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">（演習）streamlitに実装しましょう！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動いたアプリをstreamlitで動くようにします。  \n",
    "この演習では必ず実行ファイルにコーディングしてください。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※streamlit run ファイル名で実行する時は必ず実行ファイルで実行してください。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実装の流れ\n",
    "1. 固定である音声ファイルをアップロードされた音声ファイルに変更\n",
    "    1. アップローダー設置\n",
    "    1. アップロードされたら音声認識が実行されるようにする\n",
    "    1. マイク側もボタンが押されたら音声認識のコードが実行されるようにする\n",
    "1. 音声認識の言語指定を変更できるようにする\n",
    "    1. 言語候補を変数へ\n",
    "    1. セレクトボックスで選択できるようにする\n",
    "    1. 関数の引数に加える\n",
    "1. ターミナルに出力していた文字などをブラウザに出力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の手元で動いたコードをstreamlitで動くようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フロントエンドを扱うstreamlitの機能をインポート\n",
    "# 音声認識の機能をインポート\n",
    "\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    \n",
    "         # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    " #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "\n",
    " # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "\n",
    "\n",
    "def file_speech_to_text(audio_file):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "# sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "#  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "\n",
    "# 認識した文字を返す\n",
    "\n",
    "# タイトル\n",
    "\n",
    "def mic_speech_to_text():\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "file_upload = \"sample.wav\"\n",
    "\n",
    "print(\"音声認識結果:\") # 案内表示\n",
    "result_text = file_speech_to_text(file_upload) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "print(result_text) # メソッドから返ってきた値を表示\n",
    "print(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "\n",
    "result_text = mic_speech_to_text() # 選択した言語を元に音声認識開始\n",
    "print(\"音声認識結果:\") # 案内表示に変更\n",
    "print(result_text) # メソッドから返ってきた値を表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.固定である音声ファイルをアップロードされた音声ファイルに変更"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1アップローダー設置"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込みが固定だったsample.wavをアップローダーからの音声ファイルに変更します。\n",
    "\n",
    "ファイルアップロードする機能は  \n",
    "st.file_uploader(\"ここに表示したい文字\",type=ここに許可する拡張子の配列)  \n",
    "でできます。\n",
    "\n",
    "この音声認識ライブラリはwav形式しか対応していないので、許可する拡張子の配列をwavだけにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、アップロードされたファイルがfile_uploadに代入されます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2アップロードされたら音声認識が実行されるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動くコードは、無条件にファイルの音声認識をするコードを実行してしまうので、  \n",
    "これをif文を使ってアップロードされた時だけ、音声認識をするコードを実行するようにします。\n",
    "\n",
    "st.file_uploaderはなにもアップロードされていない場合、なにも存在しないNoneという値になるので、  \n",
    "file_upload != Noneという条件を使います。\n",
    "\n",
    "if文を使った条件は以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"]) # アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    print(\"ここに音声認識をするコード\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3マイク側もボタンが押されたら音声認識のコードが実行されるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手元で動くコードは、無条件にマイク入力の音声認識をするコードを実行してしまうので、  \n",
    "こちらもif文を使ってボタンが押された時だけ、音声認識をするコードを実行するようにします。\n",
    "\n",
    "if文は条件で実行されます。\n",
    "1. 変数がTrue\n",
    "1. Trueになる条件　例：1 = 1\n",
    "\n",
    "ボタンは押された時にTrueになる事を利用して、条件に組み込みます。\n",
    "\n",
    "ボタン機能はst.button(\"ここに表示したい文字\")なので以下のようなコードになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボタンが押された場合、Trueになって実行される\n",
    "\n",
    "if st.button(\"音声認識開始\"):\n",
    "    print(\"ここに音声認識をするコード\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アップローダーと実行条件を手元のコードに反映させると以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "import speech_recognition as sr # 音声認識の機能をインポート\n",
    "\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "def file_speech_to_text(audio_file):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "def mic_speech_to_text():\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "print(\"文字起こしアプリ\") # タイトル\n",
    "\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"]) # アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    print(\"音声認識結果:\") # 案内表示\n",
    "    result_text = file_speech_to_text(file_upload) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "    print(result_text) # メソッドから返ってきた値を表示\n",
    "    print(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "# ボタンが押されたら実行される\n",
    "if st.button(\"音声認識開始\"):\n",
    "    result_text = mic_speech_to_text() # 選択した言語を元に音声認識開始\n",
    "    print(\"音声認識結果:\") # 案内表示に変更\n",
    "    print(result_text) # メソッドから返ってきた値を表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.音声認識の言語指定を変更できるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "音声認識が日本語である\"ja\"で固定なので、これをセレクトボックスで選択し、反映できるようにします。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1言語候補を変数へ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ja\"を変数にします。\n",
    "\n",
    "変数set_language_listに言語コードの辞書型配列を作ります。  \n",
    "ここでは日本語と英語にしておきます。\n",
    "\n",
    "英語の言語コードはen-USです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 言語選択と、APIが認識する言語の変換リストを作成\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"ja\",\n",
    "    \"英語\" :\"en-US\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "セレクトボックスで日本語または英語を選択し、set_language_listで言語コードに変換することで、  \n",
    "音声認識に必要な言語コードを変数化します。\n",
    "\n",
    "日本語文字は.keys()で取得できるので、これを活用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['日本語', '英語'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_language_list.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2セレクトボックスで選択できるようにする"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この２つの選択肢をセレクトボックスに適応します。\n",
    "\n",
    "セレクトボックスは  st.selectbox(\"ここに表示したい項目名\",ここに配列のデータ)でできます。  \n",
    "この選ばれた選択肢をset_languageに代入します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これによって、ユーザーに見える選択肢は、set_languageである['日本語', '英語']から取得し、 \n",
    "コード実行側では、 set_language_list[set_language]とすることで、言語コードを指定します。\n",
    "\n",
    "まとめると以下のようなコードになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "import speech_recognition as sr # 音声認識の機能をインポート\n",
    "\n",
    "\n",
    "# 言語選択と、APIが認識する言語の変換リストを作成\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"ja\",\n",
    "    \"英語\" :\"en-US\",\n",
    "}\n",
    "\n",
    "# デフォルトの言語を設定\n",
    "set_language = \"日本語\"\n",
    "\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "def file_speech_to_text(audio_file):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "def mic_speech_to_text():\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=\"ja\") #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "print(\"文字起こしアプリ\") # \n",
    "\n",
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys()) # 音声認識に使う言語を選択肢として表示\n",
    "\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"]) # アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    print(\"音声認識結果:\") # 案内表示\n",
    "    result_text = file_speech_to_text(file_upload) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "    print(result_text) # メソッドから返ってきた値を表示\n",
    "    print(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "# ボタンが押されたら実行される\n",
    "if st.button(\"音声認識開始\"):\n",
    "    result_text = mic_speech_to_text() # 選択した言語を元に音声認識開始\n",
    "    print(\"音声認識結果:\") # 案内表示に変更\n",
    "    print(result_text) # メソッドから返ってきた値を表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3関数の引数に加える"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のまとめたコードでは、関数に変数である言語コードが反映されません。\n",
    "\n",
    "それぞれの関数に言語を引数に持つようにします。\n",
    "- file_speech_to_text(file_upload)\n",
    "- mic_speech_to_text()\n",
    "\n",
    "さらに関数の中の\"ja\"も言語コードの変数にします。\n",
    "\n",
    "言語はset_language  \n",
    "言語コードはset_language_list[set_language]  \n",
    "で指定できるため以下のようになります。\n",
    "\n",
    "それぞれの関数に言語を引数に持つようにします。\n",
    "- file_speech_to_text(file_upload,set_language)\n",
    "- mic_speech_to_text(set_language)\n",
    "\n",
    "関数の中の\"ja\"はset_language_list[set_language]に変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "import speech_recognition as sr # 音声認識の機能をインポート\n",
    "\n",
    "\n",
    "# 言語選択と、APIが認識する言語の変換リストを作成\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"ja\",\n",
    "    \"英語\" :\"en-US\",\n",
    "}\n",
    "\n",
    "# デフォルトの言語を設定\n",
    "set_language = \"日本語\"\n",
    "\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "def file_speech_to_text(audio_file):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=set_language_list[set_language]) #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "def mic_speech_to_text():\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=set_language_list[set_language]) #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "print(\"文字起こしアプリ\") # \n",
    "\n",
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys()) # 音声認識に使う言語を選択肢として表示\n",
    "\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"]) # アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    print(\"音声認識結果:\") # 案内表示\n",
    "    result_text = file_speech_to_text(file_upload,set_language) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "    print(result_text) # メソッドから返ってきた値を表示\n",
    "    print(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "# ボタンが押されたら実行される\n",
    "if st.button(\"音声認識開始\"):\n",
    "    result_text = mic_speech_to_text(set_language) # 選択した言語を元に音声認識開始\n",
    "    print(\"音声認識結果:\") # 案内表示に変更\n",
    "    print(result_text) # メソッドから返ってきた値を表示"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.ターミナルに出力していた文字などをブラウザに出力"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後にprintでターミナルで出力していた  \n",
    "タイトルや文字や音声を以下の４つのコードを使ってブラウザに出力します。\n",
    "\n",
    "- st.title\n",
    "- st.write\n",
    "- st.empty()\n",
    "- st.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st # フロントエンドを扱うstreamlitの機能をインポート\n",
    "import speech_recognition as sr # 音声認識の機能をインポート\n",
    "\n",
    "# 言語選択と、APIが認識する言語の変換リストを作成\n",
    "set_language_list = {\n",
    "    \"日本語\" :\"ja\",\n",
    "    \"英語\" :\"en-US\",\n",
    "}\n",
    "\n",
    "# デフォルトの言語を設定\n",
    "set_language = \"日本語\"\n",
    "\n",
    "\n",
    "# 音声ファイルと音声認識の言語を引数に音声認識をする\n",
    "def file_speech_to_text(audio_file,set_language):\n",
    "\n",
    "    # 音声ファイルを読み込み\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = sr.Recognizer().record(source) # sr.Recognizer().record(開いた音声ファイル)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=set_language_list[set_language]) #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "# 音声認識の言語を引数に音声認識をする\n",
    "def mic_speech_to_text(set_language):\n",
    "\n",
    "    # マイク入力を音声ファイルとして読み込み\n",
    "    with sr.Microphone() as source:\n",
    "        audio = sr.Recognizer().listen(source) # sr.Recognizer().listen(マイク入力)で認識準備\n",
    "\n",
    "    try:\n",
    "        text = sr.Recognizer().recognize_google(audio, language=set_language_list[set_language]) #  sr.Recognizer().recognize_google(音声データ,言語)で音声認識して、textに代入\n",
    "    except:\n",
    "        text = \"音声認識に失敗しました\"\n",
    "    return text # 認識した文字を返す\n",
    "\n",
    "st.title(\"文字起こしアプリ\") # タイトル\n",
    "st.write(\"音声認識する言語を選んでください。\") # 案内を表示\n",
    "set_language = st.selectbox(\"音声認識する言語を選んでください。\",set_language_list.keys()) # 音声認識に使う言語を選択肢として表示\n",
    "current_language_state = st.empty() # 選択肢を表示するための箱を準備\n",
    "current_language_state.write(\"選択中の言語:\" + set_language) # 選択肢を表示するための箱に選択した言語を表示\n",
    "file_upload = st.file_uploader(\"ここに音声認識したファイルをアップロードしてください。\",type=[\"wav\"]) # アップローダーを設定し、wavファイルだけ許可する設定にする\n",
    "\n",
    "# ファイルアップロードされた場合、file_uploadがNoneではなくなる\n",
    "if (file_upload !=None):\n",
    "    \n",
    "    st.write(\"音声認識結果:\") # 案内表示\n",
    "    result_text = file_speech_to_text(file_upload,set_language) # アップロードされたファイルと選択した言語を元に音声認識開始\n",
    "    st.write(result_text) # メソッドから返ってきた値を表示\n",
    "    st.audio(file_upload) # アップロードした音声をきける形で表示\n",
    "\n",
    "\n",
    "st.write(\"マイクでの音声認識はこちらのボタンから\") # 案内表示\n",
    "\n",
    "# ボタンが押されたら実行される\n",
    "if st.button(\"音声認識開始\"):\n",
    "    state = st.empty() # マイク録音中を示す為の箱を準備\n",
    "    state.write(\"音声認識中\") # 箱に案内表示書き込み\n",
    "    result_text = mic_speech_to_text(set_language) # 選択した言語を元に音声認識開始\n",
    "    state.write(\"音声認識結果:\") # 案内表示に変更\n",
    "    st.write(result_text) # メソッドから返ってきた値を表示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BookingSystem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "989f5752f561fb768d059b46974d5def8b17e29e1e5e246060e0964698096c39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
